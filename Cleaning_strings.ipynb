{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Strings\n",
    "\n",
    "we'll be working with the restaurants DataFrame which has data on various restaurants. Our ultimate goal is to create a restaurant recommendation engine, but we need to first clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yira\\Anaconda\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import process from fuzzywuzzy\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 336 entries, 0 to 335\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    336 non-null    int64 \n",
      " 1   name          336 non-null    object\n",
      " 2   addr          336 non-null    object\n",
      " 3   city          336 non-null    object\n",
      " 4   phone         336 non-null    int64 \n",
      " 5   type          336 non-null    object\n",
      " 6   cuisine_type  336 non-null    object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 18.5+ KB\n",
      "None\n",
      "   Unnamed: 0                       name                       addr  \\\n",
      "0           0  arnie morton's of chicago   435 s. la cienega blv .    \n",
      "1           1         art's delicatessen       12224 ventura blvd.    \n",
      "2           2                  campanile       624 s. la brea ave.    \n",
      "3           3                      fenix    8358 sunset blvd. west    \n",
      "4           4         grill on the alley           9560 dayton way    \n",
      "\n",
      "          city       phone      type cuisine_type  \n",
      "0  los angeles  3102461501  american      america  \n",
      "1  studio city  8187621221  american      mercian  \n",
      "2  los angeles  2139381447  american     amurican  \n",
      "3    hollywood  2138486677  american     americen  \n",
      "4  los angeles  3102760615  american    americann  \n"
     ]
    }
   ],
   "source": [
    "# Read csv\n",
    "data=pd.read_csv(\"datasets//restaurants_L2.csv\")\n",
    "\n",
    "# Info of csv\n",
    "print(data.info())\n",
    "\n",
    "# Let's see have a look in the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['america' 'mercian' 'amurican' 'americen' 'americann' 'asiian' 'italian'\n",
      " 'asiann' 'asian' 'american' 'co0ffebar' 'assina' 'southwestern'\n",
      " 'steakhouses' 'southern' 'mexicam' 'mexicana' 'itallian' 'talina'\n",
      " 'mexico' 'coffee bar' 'cofebar' 'cooffeebar' 'coffeebar' 'mexicann'\n",
      " 'mejicana' 'mexican' 'itlian']\n"
     ]
    }
   ],
   "source": [
    "# Store the unique values of cuisine_type in unique_types\n",
    "unique_types = data[\"cuisine_type\"].unique()\n",
    "\n",
    "# print the unique values\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('asian', 100), ('asiian', 91), ('asiann', 91), ('assina', 73), ('italian', 67), ('amurican', 62), ('american', 62), ('itallian', 62), ('americann', 57), ('talina', 55), ('itlian', 55), ('mexicana', 54), ('mexicann', 54), ('mejicana', 54), ('america', 50), ('mercian', 50), ('mexican', 50), ('americen', 46), ('southwestern', 36), ('southern', 31), ('co0ffebar', 26), ('coffee bar', 26), ('cooffeebar', 26), ('coffeebar', 26), ('steakhouses', 25), ('mexico', 18), ('mexicam', 17), ('cofebar', 17)]\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity of 'asian' to all values of unique_types\n",
    "print(process.extract('asian', unique_types, limit = len(unique_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('american', 100), ('americann', 94), ('america', 93), ('amurican', 88), ('americen', 88), ('mercian', 80), ('mexican', 80), ('mexicana', 75), ('mexicann', 75), ('mejicana', 75), ('mexicam', 67), ('asian', 62), ('asiian', 57), ('asiann', 57), ('mexico', 57), ('italian', 53), ('itallian', 50), ('assina', 43), ('talina', 43), ('itlian', 43), ('southwestern', 41), ('southern', 38), ('cofebar', 27), ('co0ffebar', 24), ('coffeebar', 24), ('coffee bar', 22), ('cooffeebar', 22), ('steakhouses', 21)]\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity of 'american' to all values of unique_types\n",
    "print(process.extract('american', unique_types, limit = len(unique_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('italian', 100), ('itallian', 93), ('itlian', 92), ('talina', 77), ('asian', 67), ('asiian', 62), ('asiann', 62), ('mercian', 43), ('mexican', 43), ('amurican', 40), ('american', 40), ('mexicana', 40), ('mexicann', 40), ('mejicana', 40), ('americann', 38), ('assina', 31), ('america', 29), ('mexicam', 29), ('americen', 27), ('southern', 27), ('southwestern', 26), ('steakhouses', 26), ('mexico', 15), ('cofebar', 14), ('co0ffebar', 12), ('coffee bar', 12), ('cooffeebar', 12), ('coffeebar', 12)]\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity of 'italian' to all values of unique_types\n",
    "print(process.extract('italian', unique_types, limit = len(unique_types)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the output, what do you think should be the similarity cutoff point when remapping categories?\n",
    "\n",
    "80 could be a good cutoff point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remapping categories \n",
    "In the last exercise, we determined that the distance cutoff point for remapping typos of 'american', 'asian', and 'italian' cuisine types stored in the cuisine_type column should be 80.\n",
    "\n",
    "Here, we're going to put it all together by finding matches with similarity scores equal to or higher than 80 by using fuzywuzzy.process's extract() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('italian', 100, 6), ('italian', 100, 10), ('italian', 100, 11), ('italian', 100, 16), ('italian', 100, 19)]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of matches, comparing 'italian' with the cuisine_type column\n",
    "matches = process.extract('italian', data['cuisine_type'], limit = len(data))\n",
    "\n",
    "# Inspect the first 5 matches\n",
    "print(matches[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're getting somewhere! Now we can iterate through matches to reassign similar entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the list of matches to italian\n",
    "for match in matches:\n",
    "\n",
    "  # Check whether the similarity score is greater than or equal to 80\n",
    "   if match[1]>=80:\n",
    "\n",
    "    # Select all rows where the cuisine_type is spelled this way, and set them to the correct cuisine\n",
    "    data.loc[data['cuisine_type'] == match[0], 'cuisine_type'] = 'italian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['america' 'mercian' 'amurican' 'americen' 'americann' 'asiian' 'italian'\n",
      " 'asiann' 'asian' 'american' 'co0ffebar' 'assina' 'southwestern'\n",
      " 'steakhouses' 'southern' 'mexicam' 'mexicana' 'talina' 'mexico'\n",
      " 'coffee bar' 'cofebar' 'cooffeebar' 'coffeebar' 'mexicann' 'mejicana'\n",
      " 'mexican']\n"
     ]
    }
   ],
   "source": [
    "# Store again the unique values of cuisine_type in unique_types to see changes\n",
    "unique_types2 = data[\"cuisine_type\"].unique()\n",
    "\n",
    "# print the unique values \n",
    "print(unique_types2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mexican' 'asian' 'italian' 'coffeebar' 'assina' 'southern' 'steakhouses'\n",
      " 'talina' 'mexico']\n"
     ]
    }
   ],
   "source": [
    "#we'll adapt the code to work with every restaurant type in unique_types\n",
    "\n",
    "# Iterate through unique_types\n",
    "for cuisine in unique_types:  \n",
    "  # Create a list of matches, comparing cuisine with the cuisine_type column\n",
    "  matches = process.extract(cuisine, data['cuisine_type'], limit=len(data.cuisine_type))\n",
    "\n",
    "  # Iterate through the list of matches\n",
    "  for match in matches:\n",
    "     # Check whether the similarity score is greater than or equal to 80\n",
    "    if match[1] >= 80:\n",
    "      # If it is, select all rows where the cuisine_type is spelled this way, and set them to the correct cuisine\n",
    "      data.loc[data['cuisine_type'] == match[0]] = cuisine\n",
    "      \n",
    "# Inspect the final result\n",
    "print(data['cuisine_type'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linkage\n",
    "\n",
    "\" linkage is the act of linking data from different sources regarding the same entity. But unlike joins, record linkage does not require exact matches between different pairs of data, and instead can find close matches using string similarity. This is why record linkage is effective when there are no common unique keys between the data sources you can rely upon when linking data sources such as a unique identifier.\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be9772337e76630d57b874c7eb4812959236d388181218c853d83d1703fa1a09"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
